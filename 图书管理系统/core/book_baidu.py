import json
import os
import re
from .book_modify import book_pach_db_data, book_pach_db_data_b, book_pach_index


def read_json_files_in_directory(directory):
    json_data = []
    # æ£€æŸ¥ç›®å½•æ˜¯å¦ä¸ºç©º
    if not os.listdir(directory):
        print(f"ç›®å½• {directory} ä¸ºç©ºï¼Œæ²¡æœ‰æ–‡ä»¶ã€‚")
        return json_data  # è¿”å›ç©ºå­—å…¸
    # éå†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for filename in os.listdir(directory):
        # åˆ¤æ–­æ–‡ä»¶æ˜¯å¦æ˜¯JSONæ–‡ä»¶
        if filename.endswith(".json"):
            file_path = os.path.join(directory, filename)

            # å°è¯•æ‰“å¼€å¹¶åŠ è½½JSONæ–‡ä»¶
            try:
                with open(file_path, 'r', encoding='utf-8') as file:
                    data = json.load(file)
                    json_data.append(data)
            except json.JSONDecodeError:
                print(f"æ–‡ä»¶ {filename} æ ¼å¼é”™è¯¯")
            except PermissionError:
                print(f"æ²¡æœ‰æƒé™è¯»å–æ–‡ä»¶ {filename}")
    return json_data


def read_json_file(file_path):
    """å®‰å…¨è¯»å–å•ä¸ª JSON æ–‡ä»¶å¹¶è¿”å›å†…å®¹ã€‚"""
    try:
        if not os.path.exists(file_path):
            return {}
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception:
        # å¦‚æœè¯»å–å¤±è´¥ï¼ˆä¾‹å¦‚æ–‡ä»¶æŸåï¼‰ï¼Œè¿”å›ç©ºå­—å…¸
        return {}

MAX_RECORDS = 999
FIXED_CATEGORY_CODE = '1'
DB_PREFIX = "book-"


def find_next_available_book_slot():
    base_dir = book_pach_db_data()
    """
    åŸºäºæ–‡ä»¶è¿ç»­æ€§åŸåˆ™ï¼ŒæŸ¥æ‰¾æœ€å¤§çš„æ–‡ä»¶åºå·ï¼Œå¹¶ç¡®å®šä¸‹ä¸€ä¸ªå¯ç”¨çš„å›¾ä¹¦æ§½ä½ã€‚

    :param base_dir: å­˜æ”¾ book-[N].json æ–‡ä»¶çš„åŸºç¡€ç›®å½•ã€‚
    :return: (file_path, next_full_id)
    """
    if not os.path.exists(base_dir):
        # ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºç¬¬ä¸€ä¸ªæ–‡ä»¶ book-1.json
        os.makedirs(base_dir)
        file_path = os.path.join(base_dir, f"{DB_PREFIX}1.json")
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump({}, f)
        return file_path, f"{FIXED_CATEGORY_CODE}-1-{1:03d}"

    # ----------------------------------------------------
    # 1. æŸ¥æ‰¾æœ€å¤§çš„æ–‡ä»¶åºå· (N)
    # ----------------------------------------------------
    latest_index = 0
    pattern = re.compile(f"^{DB_PREFIX}(\d+)\.json$")

    for filename in os.listdir(base_dir):
        match = pattern.match(filename)
        if match:
            latest_index = max(latest_index, int(match.group(1)))

    # å¦‚æœç›®å½•ä¸ºç©ºï¼Œåˆ™ä» book-1.json å¼€å§‹
    if latest_index == 0:
        latest_index = 1

    file_path = os.path.join(base_dir, f"{DB_PREFIX}{latest_index}.json")

    # ----------------------------------------------------
    # 2. æ£€æŸ¥æœ€å¤§çš„æ–‡ä»¶ book-N.json
    # ----------------------------------------------------
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError:
        # æ–‡ä»¶æŸåï¼šåŸºäºæ–°çš„çº¦æŸï¼Œæˆ‘ä»¬ä»ç„¶éœ€è¦è·³è¿‡å®ƒï¼Œä½†åº”è¯¥æ£€æŸ¥ä¸‹ä¸€ä¸ªæ–‡ä»¶
        print(f"ğŸš¨ è­¦å‘Š: æ–‡ä»¶ {file_path} å†…å®¹æŸåã€‚å·²è·³è¿‡æ­¤æ–‡ä»¶ã€‚")
        # ç”±äºæ–‡ä»¶è¿ç»­ï¼ŒæŸåçš„æ–‡ä»¶è§†ä¸ºâ€œå·²æ»¡â€ï¼Œæˆ‘ä»¬æ£€æŸ¥ä¸‹ä¸€ä¸ªæ–‡ä»¶ N+1
        latest_index += 1
        return create_new_book_file(base_dir, latest_index)

    current_count = len(data)

    if current_count < MAX_RECORDS:
        # æ–‡ä»¶æœªæ»¡ï¼Œç›´æ¥ä½¿ç”¨
        next_book_num = current_count + 1
        next_id = f"{FIXED_CATEGORY_CODE}-{latest_index}-{next_book_num:03d}"
        return file_path, next_id
    else:
        # æ–‡ä»¶å·²æ»¡ï¼Œåˆ›å»º book-(N+1).json
        latest_index += 1
        return create_new_book_file(base_dir, latest_index)


# è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºæ–°æ–‡ä»¶å¹¶è¿”å›ä¿¡æ¯
def create_new_book_file(base_dir, file_index):
    new_file_path = os.path.join(base_dir, f"{DB_PREFIX}{file_index}.json")
    with open(new_file_path, 'w', encoding='utf-8') as f:
        json.dump({}, f)
    print(f"åˆ›å»ºæ–°æ–‡ä»¶: {new_file_path}")
    next_id = f"{FIXED_CATEGORY_CODE}-{file_index}-{1:03d}"
    return new_file_path, next_id


DB_PREFIX_B = "book-b-"


def find_next_available_copy_slot():
    base_dir = book_pach_db_data_b()
    """
    åŸºäºæ–‡ä»¶è¿ç»­æ€§åŸåˆ™ï¼ŒæŸ¥æ‰¾æœ€å¤§çš„å‰¯æœ¬æ–‡ä»¶åºå·ï¼Œå¹¶è¿”å›è¯¥æ–‡ä»¶å‰©ä½™çš„å­˜å‚¨å®¹é‡ã€‚
    """
    if not os.path.exists(base_dir):
        # ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºç¬¬ä¸€ä¸ªæ–‡ä»¶ book-b-1.json
        os.makedirs(base_dir)
        file_path = os.path.join(base_dir, f"{DB_PREFIX_B}1.json")
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump({}, f)
        return file_path, MAX_RECORDS

    # ----------------------------------------------------
    # 1. æŸ¥æ‰¾æœ€å¤§çš„æ–‡ä»¶åºå· (N)
    # ----------------------------------------------------
    latest_index = 0
    pattern = re.compile(f"^{DB_PREFIX_B}(\d+)\.json$")

    for filename in os.listdir(base_dir):
        match = pattern.match(filename)
        if match:
            latest_index = max(latest_index, int(match.group(1)))

    if latest_index == 0:
        latest_index = 1

    file_path = os.path.join(base_dir, f"{DB_PREFIX_B}{latest_index}.json")

    # ----------------------------------------------------
    # 2. æ£€æŸ¥æœ€å¤§çš„æ–‡ä»¶ book-b-N.json
    # ----------------------------------------------------
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError:
        # æ–‡ä»¶æŸåï¼šè·³è¿‡ï¼Œå¹¶è¿”å›ä¸‹ä¸€ä¸ªæ–°æ–‡ä»¶ (N+1) çš„æœ€å¤§å®¹é‡
        print(f"ğŸš¨ è­¦å‘Š: å‰¯æœ¬æ–‡ä»¶ {file_path} å†…å®¹æŸåã€‚å·²è·³è¿‡æ­¤æ–‡ä»¶ã€‚")
        latest_index += 1
        return create_new_copy_file(base_dir, latest_index)

    current_count = len(data)

    if current_count < MAX_RECORDS:
        # æ–‡ä»¶æœªæ»¡ï¼Œè®¡ç®—å‰©ä½™å®¹é‡å¹¶è¿”å›
        remaining_slots = MAX_RECORDS - current_count
        return file_path, remaining_slots
    else:
        # æ–‡ä»¶å·²æ»¡ï¼Œåˆ›å»º book-b-(N+1).json
        latest_index += 1
        return create_new_copy_file(base_dir, latest_index)


# è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºæ–°å‰¯æœ¬æ–‡ä»¶å¹¶è¿”å›ä¿¡æ¯
def create_new_copy_file(base_dir, file_index):
    new_file_path = os.path.join(base_dir, f"{DB_PREFIX_B}{file_index}.json")
    with open(new_file_path, 'w', encoding='utf-8') as f:
        json.dump({}, f)
    print(f"åˆ›å»ºæ–°å‰¯æœ¬æ–‡ä»¶: {new_file_path}")
    return new_file_path, MAX_RECORDS


def get_book_record_by_id(book_id):
    """
    æ ¹æ®æ¯æœ¬ ID æŸ¥æ‰¾å¹¶è¿”å›è¯¥ä¹¦çš„å®Œæ•´ä¿¡æ¯è®°å½•ã€‚

    :param book_id: å®Œæ•´çš„æ¯æœ¬ ID (e.g., '1-3-010')
    :return: æ‰¾åˆ°çš„å›¾ä¹¦è®°å½•å­—å…¸ (e.g., {'name': '...', 'author': '...'}),
             å¦‚æœæœªæ‰¾åˆ°æˆ– ID æ ¼å¼é”™è¯¯ï¼Œè¿”å› Noneã€‚
    """
    try:
        # 1. è§£æ ID ä»¥ç¡®å®šæ–‡ä»¶åºå·
        # ID æ ¼å¼: FIXED_CATEGORY_CODE - FILE_INDEX - BOOK_NUM
        # æˆ‘ä»¬éœ€è¦è·å– FILE_INDEX (ID çš„ç¬¬äºŒéƒ¨åˆ†)
        parts = book_id.split('-')
        if len(parts) != 3:
            print(f"è­¦å‘Š: æ¯æœ¬ ID æ ¼å¼é”™è¯¯: {book_id}")
            return None

        file_index = parts[1]  # ä¾‹å¦‚ï¼š'1-3-010' -> '3'

    except Exception:
        print(f"è­¦å‘Š: æ— æ³•è§£æ ID {book_id}")
        return None

    # 2. æ„é€ æ–‡ä»¶è·¯å¾„
    base_dir = book_pach_db_data()  # è·å–æ¯æœ¬æ–‡ä»¶ç›®å½•
    file_path = os.path.join(base_dir, f"book-{file_index}.json")

    # 3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(file_path):
        # ç†è®ºä¸Šï¼Œå¦‚æœ ID æ˜¯æœ‰æ•ˆçš„ï¼Œæ–‡ä»¶åº”è¯¥å­˜åœ¨
        print(f"é”™è¯¯: æ‰¾ä¸åˆ° ID {book_id} å¯¹åº”çš„æ–‡ä»¶: {file_path}")
        return None

    # 4. è¯»å–æ–‡ä»¶å¹¶æŸ¥æ‰¾æŒ‡å®š ID
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

            # æŸ¥æ‰¾å¹¶è¿”å›è¯¥ ID å¯¹åº”çš„è®°å½•
            return data.get(book_id)

    except json.JSONDecodeError:
        print(f"è­¦å‘Š: æ–‡ä»¶ {file_path} å†…å®¹æŸåï¼Œæ— æ³•è¯»å–ã€‚")
        return None
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None


def find_relevant_copy_files(mother_id):
    """
    ä½¿ç”¨è¾¹ç•Œç´¢å¼•ï¼ŒæŸ¥æ‰¾æ‰€æœ‰å¯èƒ½åŒ…å«ç›®æ ‡æ¯æœ¬å‰¯æœ¬çš„æ–‡ä»¶ååˆ—è¡¨ã€‚

    :param mother_id: ç›®æ ‡æ¯æœ¬ ID (e.g., '1-3-010')
    :return: åŒ…å«ç›¸å…³å‰¯æœ¬çš„æ–‡ä»¶ååˆ—è¡¨ (e.g., ['book-b-2.json', 'book-b-3.json'])
    """
    index_pach = book_pach_index()
    boundary_index_path = os.path.join(index_pach, "book-sw-index.json")

    boundary_index = read_json_file(boundary_index_path)

    if not boundary_index:
        print("è­¦å‘Š: è¾¹ç•Œç´¢å¼•æ–‡ä»¶ä¸ºç©ºæˆ–è¯»å–å¤±è´¥ã€‚")
        return []

    relevant_files = []

    # æŒ‰æ–‡ä»¶åè‡ªç„¶æ’åºï¼Œç¡®ä¿æŒ‰é¡ºåºè¯»å–
    sorted_filenames = sorted(boundary_index.keys())

    # æŸ¥æ‰¾è¿‡ç¨‹ï¼šæˆ‘ä»¬å¯»æ‰¾æ¯æœ¬ ID ä½äº [start_mid, end_mid] èŒƒå›´å†…çš„æ‰€æœ‰æ–‡ä»¶ã€‚

    # æŸ¥æ‰¾èµ·ç‚¹ï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ª start_mid <= mother_id çš„æ–‡ä»¶
    start_found = False

    for filename in sorted_filenames:
        start_mid, end_mid = boundary_index[filename]

        # 1. ç¡®å®šæŸ¥æ‰¾çš„èµ·å§‹ç‚¹ (start_mid <= mother_id)
        if not start_found:
            if start_mid <= mother_id:
                start_found = True
            else:
                # ç›®æ ‡æ¯æœ¬ ID å°äºå½“å‰æ–‡ä»¶èµ·å§‹ç‚¹ï¼Œè¯´æ˜å®ƒåœ¨æ›´æ—©çš„æ–‡ä»¶ä¸­ï¼Œ
                # æˆ–è€…å®ƒæ ¹æœ¬ä¸å­˜åœ¨ï¼ˆå¦‚æœè¿™æ˜¯ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼‰ã€‚
                continue

        # 2. ä»èµ·å§‹ç‚¹å¼€å§‹ï¼Œåˆ¤æ–­æ˜¯å¦åŒ…å«ç›®æ ‡æ¯æœ¬çš„å‰¯æœ¬ã€‚
        # åªè¦æ¯æœ¬ ID ä½äºå½“å‰æ–‡ä»¶çš„ [èµ·å§‹æ¯æœ¬ ID, ç»“æŸæ¯æœ¬ ID] èŒƒå›´å†…ï¼Œå°±è¯´æ˜è¯¥æ–‡ä»¶åŒ…å«ç›®æ ‡å‰¯æœ¬ã€‚
        if start_mid <= mother_id <= end_mid:
            relevant_files.append(filename)
        elif mother_id < start_mid:
            # å¦‚æœ mother_id å°äºå½“å‰æ–‡ä»¶çš„èµ·å§‹æ¯æœ¬ IDï¼Œè¯´æ˜ç›®æ ‡æ¯æœ¬çš„å‰¯æœ¬å·²ç»å…¨éƒ¨ç»“æŸã€‚
            # å› ä¸ºæ•°æ®æ˜¯æŒ‰ mother_id æœ‰åºæ’åˆ—çš„ï¼Œæ‰€ä»¥å¯ä»¥æå‰ç»ˆæ­¢æŸ¥æ‰¾ã€‚
            break

        # å¦‚æœ mother_id > end_mid, æ„å‘³ç€å½“å‰æ¯æœ¬çš„å‰¯æœ¬å·²ç»åœ¨è¿™ä¸ªæ–‡ä»¶ç»“æŸäº†ï¼Œ
        # ä½†æˆ‘ä»¬å¿…é¡»ç»§ç»­æ£€æŸ¥ä¸‹ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´åˆ°æ»¡è¶³ mother_id < start_mid çš„æ¡ä»¶æ‰èƒ½åœæ­¢ã€‚

    return relevant_files


def get_all_copies_by_mother_id_optimized(mother_id):
    """
    æ ¹æ®æ¯æœ¬ ID é«˜æ•ˆæ‰¾åˆ°å…¶æ‰€æœ‰å‰¯æœ¬å†…å®¹åˆ—è¡¨ï¼ˆä»…è¿”å›å‰¯æœ¬ä¿¡æ¯ï¼‰ã€‚
    åˆ©ç”¨è¾¹ç•Œç´¢å¼•å®šä½æ–‡ä»¶ï¼Œå¹¶åˆ©ç”¨ ID ç»“æ„ç›´æ¥åŒ¹é…ã€‚

    :param mother_id: å®Œæ•´çš„æ¯æœ¬ ID (e.g., '1-3-010')
    :return: åŒ…å«æ‰€æœ‰å‰¯æœ¬ä¿¡æ¯å­—å…¸çš„åˆ—è¡¨, æ ¼å¼ä¸º [{...}, {...}]ã€‚
    """

    # --- é˜¶æ®µ 1: å®šä½ç›¸å…³å‰¯æœ¬æ–‡ä»¶ ---
    relevant_files = find_relevant_copy_files(mother_id)

    if not relevant_files:
        return []

    # --- é˜¶æ®µ 2: é€æ–‡ä»¶è¯»å–å¹¶æå–å‰¯æœ¬ ---

    all_copy_details = []
    base_copy_dir = book_pach_db_data_b()

    for filename in relevant_files:
        file_path = os.path.join(base_copy_dir, filename)

        # è¯»å–æ–‡ä»¶å†…å®¹ï¼š{å‰¯æœ¬ID: å‰¯æœ¬ä¿¡æ¯å­—å…¸}
        copy_records_dict = read_json_file(file_path)

        if not copy_records_dict:
            continue

        for copy_id, copy_info in copy_records_dict.items():

            # ä»å‰¯æœ¬ ID æå–æ¯æœ¬ ID
            current_mother_id = '-'.join(copy_id.split('-')[:-1])

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡æ¯æœ¬çš„å‰¯æœ¬
            if current_mother_id == mother_id:
                # â­ï¸ å…³é”®ä¿®æ”¹ï¼šå°† copy_id é”®/å€¼å¯¹æ·»åŠ åˆ°å‰¯æœ¬ä¿¡æ¯å­—å…¸ä¸­
                # è¿™æ ·åšå¯ä»¥ç¡®ä¿ UI ç«¯çš„è¡¨æ ¼èƒ½å¤Ÿé€šè¿‡ 'copy_id' é”®è·å–åˆ°å€¼ã€‚
                # ä½¿ç”¨ .copy() ä»¥å…ä¿®æ”¹åŸå§‹æ•°æ®åº“è®°å½•
                copy_detail = copy_info.copy()
                copy_detail['copy_id'] = copy_id

                all_copy_details.append(copy_detail)

            elif current_mother_id > mother_id:
                # ä¼˜åŒ–ï¼šæŒ‰æ¯æœ¬ ID æ’åºï¼Œè¶…å‡ºèŒƒå›´å³å¯åœæ­¢å½“å‰æ–‡ä»¶çš„æŸ¥æ‰¾ã€‚
                break

    # --- é˜¶æ®µ 3: è¿”å›ç»“æœ ---
    return all_copy_details
